task:
  id: "r2-t3-model-registry"
  name: "Build Multi-Provider Model Registry"
  session_size: "Complete model registry with Gemini, OpenAI, and Anthropic support"
  
  context:
    why: "Provider-agnostic model management with fallback and configuration handling"
    integrates_with: ["agent-factory", "database-schema"]
    references:
      - "masterplan model registry (lines 816-942)"
      - "roadmap phase 2 model provider support"
    
  build_spec:
    creates:
      - "services/agent-engine/src/models/registry.py"
      - "services/agent-engine/src/models/providers/__init__.py"
      - "services/agent-engine/src/models/providers/gemini.py"
      - "services/agent-engine/src/models/providers/openai.py"
      - "services/agent-engine/src/models/providers/anthropic.py"
      - "services/agent-engine/tests/test_model_registry.py"
    modifies:
      - "src/agents/factory.py (use model registry)"
      - "src/config.py (add API key configs)"
      - "scripts/seed.py (add model provider data)"
    uses:
      - "Provider-specific configurations"
      - "Environment variables for API keys"
      - "Database for provider settings"
    
  implementation_guide:
    start_with: "Create ModelRegistry class with provider configurations"
    core_logic:
      - "ModelConfig dataclass for configurations"
      - "Provider detection from model names"
      - "Default parameters per model"
      - "Parameter override capability"
      - "Availability checking (basic)"
      - "Provider-specific adapters"
      - "Fallback handling logic"
    connects_to:
      - "Agent factory for model selection"
      - "Database for provider configs"
      - "Environment for API keys"
    keeps_simple:
      - "Static provider configurations for now"
      - "No actual API calls yet (mock for testing)"
      - "Basic availability (just return true/false)"
      - "No rate limiting or quotas"
      - "No cost tracking"
    
  local_validation:
    run_commands:
      - "python -m pytest tests/test_model_registry.py -v"
      - "python scripts/test_model_configs.py"
    verify_endpoints:
      - "Registry returns correct model strings"
      - "Parameters merge correctly"
      - "Provider detection works"
    check_functionality:
      - "Can get config for each provider"
      - "Override parameters work"
      - "Unknown models raise errors"
      - "Availability check returns boolean"
      - "Provider adapters initialized"
    
  session_notes:
    context_critical:
      - "Model names determine provider"
      - "Each provider has specific parameters"
      - "API keys from environment variables"
      - "Configurations stored in database"
    remember_for_later:
      - "Model string formats per provider"
      - "Parameter names differ by provider"
      - "Fallback patterns for failures"
      - "Cost implications of models"

  implementation_checklist:
    - "Create ModelRegistry class"
    - "Define ModelConfig dataclass"
    - "Add provider configurations"
    - "Implement get_config method"
    - "Add provider detection logic"
    - "Create provider adapters (stubs)"
    - "Build availability checking"
    - "Write comprehensive tests"
    - "Update seed data"

  provider_configurations:
    gemini:
      models:
        - name: "gemini-2.0-flash"
          string: "gemini-2.0-flash"
          defaults:
            temperature: 0.3
            max_tokens: 2000
            top_p: 0.95
        - name: "gemini-1.5-pro"
          string: "gemini-1.5-pro"
          defaults:
            temperature: 0.5
            max_tokens: 4000
            top_p: 0.95
    
    openai:
      models:
        - name: "gpt-4-turbo"
          string: "gpt-4-turbo-preview"
          defaults:
            temperature: 0.3
            max_tokens: 2000
            top_p: 1.0
        - name: "gpt-4o"
          string: "gpt-4o"
          defaults:
            temperature: 0.3
            max_tokens: 2000
            top_p: 1.0
    
    anthropic:
      models:
        - name: "claude-3-opus"
          string: "claude-3-opus-20240229"
          defaults:
            temperature: 0.3
            max_output_tokens: 2000
            top_p: 1.0
        - name: "claude-3-sonnet"
          string: "claude-3-sonnet-20240229"
          defaults:
            temperature: 0.3
            max_output_tokens: 2000
            top_p: 1.0

  provider_detection:
    logic: |
      if model_name.startswith("gemini"):
          return "gemini"
      elif model_name.startswith("gpt"):
          return "openai"
      elif model_name.startswith("claude"):
          return "anthropic"
      else:
          raise ValueError(f"Unknown provider for: {model_name}")

  mock_availability:
    implementation: |
      async def check_model_availability(self, model_name: str) -> bool:
          # For now, just check if model is known
          try:
              self.get_config(model_name)
              return True
          except ValueError:
              return False